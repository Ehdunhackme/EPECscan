{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1372e5ddcb51405c95b726da04cc5a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error processing pos_0_frame_15_4_aug_5.png: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\copy.cpp:1026: error: (-215:Assertion failed) top >= 0 && bottom >= 0 && left >= 0 && right >= 0 && _src.dims() <= 2 in function 'cv::copyMakeBorder'\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7704b6c69d8d4766827e0e5cec35ee43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error processing pos_0_frame_1_1_aug_8.png: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\copy.cpp:1026: error: (-215:Assertion failed) top >= 0 && bottom >= 0 && left >= 0 && right >= 0 && _src.dims() <= 2 in function 'cv::copyMakeBorder'\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c1202290d746c69fe3b5daa744a664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error processing pos_0_frame_1_2_aug_1.png: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\copy.cpp:1026: error: (-215:Assertion failed) top >= 0 && bottom >= 0 && left >= 0 && right >= 0 && _src.dims() <= 2 in function 'cv::copyMakeBorder'\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 105\u001b[0m\n\u001b[0;32m    102\u001b[0m         generate_lime_batch(images, save_folder)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Usage example: Generate LIME explanations for all images in the specified folder\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m \u001b[43mgenerate_lime_for_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 94\u001b[0m, in \u001b[0;36mgenerate_lime_for_folder\u001b[1;34m(image_folder, save_folder, batch_size)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# Process batch of images\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(images) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size:\n\u001b[1;32m---> 94\u001b[0m         \u001b[43mgenerate_lime_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m         images \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[14], line 45\u001b[0m, in \u001b[0;36mgenerate_lime_batch\u001b[1;34m(images, save_folder)\u001b[0m\n\u001b[0;32m     42\u001b[0m explainer \u001b[38;5;241m=\u001b[39m LimeImageExplainer()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Explain the model's predictions for the image\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass the image\u001b[39;49;00m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Get the image and mask for the explanation\u001b[39;00m\n\u001b[0;32m     53\u001b[0m lime_image, mask \u001b[38;5;241m=\u001b[39m explanation\u001b[38;5;241m.\u001b[39mget_image_and_mask(\n\u001b[0;32m     54\u001b[0m     explanation\u001b[38;5;241m.\u001b[39mtop_labels[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     55\u001b[0m     positive_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     min_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m  \u001b[38;5;66;03m# Adjust as per your preference\u001b[39;00m\n\u001b[0;32m     59\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dunli\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lime\\lime_image.py:190\u001b[0m, in \u001b[0;36mLimeImageExplainer.explain_instance\u001b[1;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hide_color \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(segments):\n\u001b[0;32m    189\u001b[0m         fudged_image[segments \u001b[38;5;241m==\u001b[39m x] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 190\u001b[0m             \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m[\u001b[49m\u001b[43msegments\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    191\u001b[0m             np\u001b[38;5;241m.\u001b[39mmean(image[segments \u001b[38;5;241m==\u001b[39m x][:, \u001b[38;5;241m1\u001b[39m]),\n\u001b[0;32m    192\u001b[0m             np\u001b[38;5;241m.\u001b[39mmean(image[segments \u001b[38;5;241m==\u001b[39m x][:, \u001b[38;5;241m2\u001b[39m]))\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    194\u001b[0m     fudged_image[:] \u001b[38;5;241m=\u001b[39m hide_color\n",
      "File \u001b[1;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from lime.lime_image import LimeImageExplainer\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define paths (adjust these based on your actual paths)\n",
    "base_path = r'C:\\Users\\dunli\\Documents\\STSY-project-main'\n",
    "model_weights_path = os.path.join(base_path, 'Training_Code', 'runs', 'detect', 'train16', 'weights', 'best.pt')\n",
    "image_path = os.path.join(base_path, 'Training Data', 'test', 'images')\n",
    "save_path = os.path.join(base_path, 'Lime tested image')\n",
    "\n",
    "# Load the YOLOv5 model\n",
    "model = YOLO(model_weights_path)  # Replace with your actual model path\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # Ensure image is in RGB format\n",
    "        resized_image = image.resize((640, 640))  # Resize to model input size\n",
    "        return np.array(resized_image)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing image {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Function to predict with the YOLO model\n",
    "def predict(input_image):\n",
    "    results = model(input_image, imgsz=640)  # Adjust size as per your model's input size requirement\n",
    "    # Assuming results is a list containing detection results, and you want the first result\n",
    "    output = results.pandas().xyxy[0].to_numpy()  # Convert to numpy array\n",
    "    return output\n",
    "\n",
    "# Function to generate LIME explanations for images in a batch\n",
    "def generate_lime_batch(images, save_folder):\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    for image_file, image in images.items():\n",
    "        try:\n",
    "            image_name, ext = os.path.splitext(image_file)\n",
    "\n",
    "            # Create the LIME explainer\n",
    "            explainer = LimeImageExplainer()\n",
    "\n",
    "            # Explain the model's predictions for the image\n",
    "            explanation = explainer.explain_instance(\n",
    "                image,  # Pass the image\n",
    "                predict,\n",
    "                top_labels=5,\n",
    "                num_samples=1000,\n",
    "            )\n",
    "\n",
    "            # Get the image and mask for the explanation\n",
    "            lime_image, mask = explanation.get_image_and_mask(\n",
    "                explanation.top_labels[0],\n",
    "                positive_only=False,\n",
    "                num_features=10,\n",
    "                hide_rest=False,\n",
    "                min_weight=0.01  # Adjust as per your preference\n",
    "            )\n",
    "\n",
    "            # Normalize the image to the [0, 1] range\n",
    "            lime_image = (lime_image - np.min(lime_image)) / (np.max(lime_image) - np.min(lime_image))\n",
    "\n",
    "            # Save the LIME image\n",
    "            lime_image_path = os.path.join(save_folder, f\"{image_name}_lime.jpg\")\n",
    "            plt.imsave(lime_image_path, lime_image)\n",
    "\n",
    "            print(f\"Processed {image_file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_file}: {str(e)}\")\n",
    "\n",
    "# Function to generate LIME explanations for all images in a directory\n",
    "def generate_lime_for_folder(image_folder, save_folder, batch_size=10):\n",
    "    if not os.path.exists(image_folder):\n",
    "        raise FileNotFoundError(f\"The directory '{image_folder}' does not exist or is inaccessible.\")\n",
    "\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    images = {}\n",
    "    for image_file in os.listdir(image_folder):\n",
    "        try:\n",
    "            image_file_path = os.path.join(image_folder, image_file)\n",
    "\n",
    "            # Preprocess the image\n",
    "            image = preprocess_image(image_file_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "\n",
    "            images[image_file] = image\n",
    "\n",
    "            # Process batch of images\n",
    "            if len(images) >= batch_size:\n",
    "                generate_lime_batch(images, save_folder)\n",
    "                images = {}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_file}: {str(e)}\")\n",
    "\n",
    "    # Process any remaining images in the last batch\n",
    "    if images:\n",
    "        generate_lime_batch(images, save_folder)\n",
    "\n",
    "# Usage example: Generate LIME explanations for all images in the specified folder\n",
    "generate_lime_for_folder(image_folder=image_path, save_folder=save_path, batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from lime import lime_image\n",
    "from ultralytics import YOLO  # Replace with UltraLytics import method\n",
    "\n",
    "# Load UltraLytics YOLOv5 model\n",
    "def load_ultralytics_model(weights_path):\n",
    "    model = Model(weights_path)\n",
    "    return model\n",
    "\n",
    "# Function to perform YOLOv5 prediction using UltraLytics\n",
    "def ultralytics_yolo_predict(image_path, model):\n",
    "    img = cv2.imread(image_path)  # Load image\n",
    "    # Process image to fit UltraLytics YOLOv5 input requirements, e.g., resizing, normalization\n",
    "    results = model(img)  # Perform prediction\n",
    "    return results.xyxy[0]  # Assuming UltraLytics provides bounding box coordinates directly\n",
    "\n",
    "# Function to use LIME for explaining UltraLytics YOLOv5 predictions\n",
    "def explain_ultralytics_yolo_prediction(image_path, model):\n",
    "    explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "    # Function to get predictions from UltraLytics YOLOv5 model\n",
    "    def ultralytics_yolo_predict_fn(images):\n",
    "        return ultralytics_yolo_predict(images, model)\n",
    "\n",
    "    # Explain prediction\n",
    "    explanation = explainer.explain_instance(image_path, ultralytics_yolo_predict_fn, top_labels=5, hide_color=0, num_samples=1000)\n",
    "\n",
    "    return explanation\n",
    "\n",
    "# Folder containing test images\n",
    "folder_path = r'C:\\Users\\dunli\\Documents\\STSY-project-main\\Training Data\\test\\images'\n",
    "\n",
    "# List all files in the folder\n",
    "image_files = os.listdir(folder_path)\n",
    "\n",
    "# Load UltraLytics YOLOv5 model\n",
    "ultralytics_yolov5_model = load_ultralytics_model('path_to_ultralytics_weights.pt')\n",
    "\n",
    "# Iterate through each image file\n",
    "for image_file in image_files:\n",
    "    if image_file.endswith('.jpg') or image_file.endswith('.png'):  # Adjust based on your image formats\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        print(f\"Explaining predictions for {image_path}...\")\n",
    "        explanation = explain_ultralytics_yolo_prediction(image_path, ultralytics_yolov5_model)\n",
    "        # Optionally, you can save or display the explanation here\n",
    "        # explanation.show_in_notebook()\n",
    "        # Save explanation as needed\n",
    "        explanation.save_to_file(f'explanation_{image_file}.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
