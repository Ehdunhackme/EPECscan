{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlime_image\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LimeImageExplainer\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO  \u001b[38;5;66;03m# Assuming you're using the Ultralytics YOLOv8 implementation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dunli\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\__init__.py:125\u001b[0m\n\u001b[0;32m    123\u001b[0m is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_load_library_flags:\n\u001b[1;32m--> 125\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mkernel32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadLibraryExW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0x00001100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     last_error \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mget_last_error()\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m last_error \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m126\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from lime.lime_image import LimeImageExplainer\n",
    "from PIL import Image\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO  # Assuming you're using the Ultralytics YOLOv8 implementation\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8m.pt')  # Replace with your actual model path\n",
    "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.eval()\n",
    "\n",
    "# Define a function to preprocess the image\n",
    "def preprocess(image):\n",
    "    # Implement preprocessing specific to YOLOv8 if necessary\n",
    "    image = np.array(image) / 255.0  # Normalize to [0, 1]\n",
    "    return torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "# Define a function to predict with the model\n",
    "def predict(input_image):\n",
    "    input_image = torch.tensor(input_image, dtype=torch.float32)\n",
    "    if input_image.dim() == 4:\n",
    "        input_image = input_image.permute(0, 3, 1, 2)  # Permute the dimensions\n",
    "    input_image = input_image.to('cuda' if torch.cuda.is_available() else 'cpu')  # Move to the appropriate device\n",
    "    with torch.no_grad():\n",
    "        output = model(input_image)\n",
    "    return output[0].numpy()  # Assuming the model returns a tensor, convert to numpy array\n",
    "\n",
    "def generate_lime(image_path=None, save_path=None):\n",
    "    if image_path is None:\n",
    "        test_data_path = \"data/test/Task 1/\"\n",
    "        for image_file in os.listdir(test_data_path):\n",
    "            print(\"Processing\", image_file)\n",
    "            image_path = os.path.join(test_data_path, image_file)\n",
    "            image_name = os.path.splitext(image_file)[0]\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            width, height = image.size\n",
    "            image = preprocess(image)\n",
    "            image = image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "            # Create the LIME explainer\n",
    "            explainer = LimeImageExplainer()\n",
    "\n",
    "            # Explain the model's predictions for the image\n",
    "            explanation = explainer.explain_instance(\n",
    "                image[0].permute(1, 2, 0).numpy(),\n",
    "                predict,\n",
    "                top_labels=5,\n",
    "                num_samples=1000,\n",
    "            )\n",
    "\n",
    "            # Get the image and mask for the explanation\n",
    "            lime_image, mask = explanation.get_image_and_mask(\n",
    "                explanation.top_labels[0],\n",
    "                positive_only=False,\n",
    "                num_features=10,\n",
    "                hide_rest=False,\n",
    "            )\n",
    "\n",
    "            # Normalize the image to the [0, 1] range\n",
    "            lime_image = (lime_image - np.min(lime_image)) / (np.max(lime_image) - np.min(lime_image))\n",
    "\n",
    "            # Save the LIME image\n",
    "            os.makedirs(\"docs/evaluation/lime/\", exist_ok=True)\n",
    "            lime_image_path = f\"docs/evaluation/lime/{image_name}.jpg\"\n",
    "            plt.imsave(lime_image_path, lime_image)\n",
    "\n",
    "            # Resize the image to the original size\n",
    "            lime_image = Image.open(lime_image_path)\n",
    "            lime_image = lime_image.resize((width, height))\n",
    "            lime_image.save(lime_image_path)\n",
    "\n",
    "    else:\n",
    "        print(\"Processing\", image_path)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        width, height = image.size\n",
    "        image = preprocess(image)\n",
    "        image = image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Create the LIME explainer\n",
    "        explainer = LimeImageExplainer()\n",
    "\n",
    "        # Explain the model's predictions for the image\n",
    "        explanation = explainer.explain_instance(\n",
    "            image[0].permute(1, 2, 0).numpy(), predict, top_labels=5, num_samples=1000\n",
    "        )\n",
    "\n",
    "        # Get the image and mask for the explanation\n",
    "        lime_image, mask = explanation.get_image_and_mask(\n",
    "            explanation.top_labels[0],\n",
    "            positive_only=False,\n",
    "            num_features=10,\n",
    "            hide_rest=False,\n",
    "        )\n",
    "\n",
    "        # Normalize the image to the [0, 1] range\n",
    "        lime_image = (lime_image - np.min(lime_image)) / (np.max(lime_image) - np.min(lime_image))\n",
    "\n",
    "        # Save the LIME image\n",
    "        plt.imsave(save_path, lime_image)\n",
    "\n",
    "        # Resize the image to the original size\n",
    "        lime_image = Image.open(save_path)\n",
    "        lime_image = lime_image.resize((width, height))\n",
    "        lime_image.save(save_path)\n",
    "\n",
    "# Example usage\n",
    "generate_lime(image_path='path/to/your/image.jpg', save_path='path/to/save/lime_image.jpg')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
